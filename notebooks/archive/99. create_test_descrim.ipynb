{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, LeakyReLU, Input \n",
    "from keras.layers import Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_initializer = RandomNormal(stddev=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstanceNormalization(Layer):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super(InstanceNormalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.scale = self.add_weight(\n",
    "            name='scale',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer='ones',\n",
    "            trainable=True)\n",
    "        self.offset = self.add_weight(\n",
    "            name='offset',\n",
    "            shape=input_shape[-1:],\n",
    "            initializer='zeros',\n",
    "            trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
    "        normalized = (x - mean) * inv\n",
    "        return self.scale * normalized + self.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_block(x, filters, kernel_size=4, strides=2, padding='same'):\n",
    "    \"\"\"Single block of the discriminator\"\"\"\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        kernel_initializer=weight_initializer\n",
    "    )(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape=(256, 256, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # First layer doesn't use instance normalization\n",
    "    x = discriminator_block(inputs, 64, strides=1)\n",
    "    \n",
    "    # Downsampling layers with instance normalization\n",
    "    x = discriminator_block(x, 128)\n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    x = discriminator_block(x, 256) \n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    x = discriminator_block(x, 512)\n",
    "    x = InstanceNormalization()(x)\n",
    "    \n",
    "    # Final layer\n",
    "    x = Conv2D(\n",
    "        filters=1,\n",
    "        kernel_size=4,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer=weight_initializer\n",
    "    )(x)\n",
    "    \n",
    "    return Model(inputs, x, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193 files belonging to 1 classes.\n",
      "Using 955 files for training.\n",
      "Found 7037 files belonging to 1 classes.\n",
      "Using 5630 files for training.\n"
     ]
    }
   ],
   "source": [
    "#Make the dataset\n",
    "from cycleganstyletransfer.config import DATA_DIR\n",
    "data_dir = DATA_DIR / \"raw\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "\n",
    "monet_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir / \"Monet\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=None\n",
    ")\n",
    "\n",
    "images_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir / \"Images\" ,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 10#max(len(monet_ds), len(images_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disciminator_loss(real_monet, image):\n",
    "    real_loss = tf.reduce_mean(tf.math.squared_difference(real_monet, tf.ones_like(real_monet)))\n",
    "    fake_loss = tf.reduce_mean(tf.math.squared_difference(image, tf.zeros_like(image)))\n",
    "    total_loss = 0.5 * (real_loss + fake_loss)\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def domain_discrimination_loss(domain1_output, domain2_output):\n",
    "    \"\"\"Try to label domain1 as 1 and domain2 as 0\"\"\"\n",
    "    real_loss = tf.reduce_mean(tf.math.squared_difference(domain1_output, tf.ones_like(domain1_output)))\n",
    "    fake_loss = tf.reduce_mean(tf.math.squared_difference(domain2_output, tf.zeros_like(domain2_output)))\n",
    "    return 0.5 * (real_loss + fake_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monet Classification Accuracy: 37.40%\n",
      "Photo Classification Accuracy: 64.36%\n",
      "Total Accuracy: 50.88%\n",
      "\n",
      "Epoch 1/3\n",
      "Progress: 10.0%\n",
      "Weight before: 0.018524071\n",
      "\n",
      "Weight after:  0.018724069\n",
      "Progress: 20.0%\n",
      "Weight before: 0.018724069\n",
      "\n",
      "Weight after:  0.01892801\n",
      "Progress: 30.0%\n",
      "Weight before: 0.01892801\n",
      "\n",
      "Weight after:  0.019147845\n",
      "Progress: 40.0%\n",
      "Weight before: 0.019147845\n",
      "\n",
      "Weight after:  0.019317245\n",
      "Progress: 50.0%\n",
      "Weight before: 0.019317245\n",
      "\n",
      "Weight after:  0.01941621\n",
      "Progress: 60.0%\n",
      "Weight before: 0.01941621\n",
      "\n",
      "Weight after:  0.019544443\n",
      "Progress: 70.0%\n",
      "Weight before: 0.019544443\n",
      "\n",
      "Weight after:  0.019574102\n",
      "Progress: 80.0%\n",
      "Weight before: 0.019574102\n",
      "\n",
      "Weight after:  0.019536678\n",
      "Progress: 90.0%\n",
      "Weight before: 0.019536678\n",
      "\n",
      "Weight after:  0.019570908\n",
      "Progress: 100.0%\n",
      "Weight before: 0.019570908\n",
      "\n",
      "Weight after:  0.019571759\n",
      "\n",
      "Epoch 1 Loss: 1.8651\n",
      "Avg Monet Score: 0.002 (should be ~1)\n",
      "Avg Photo Score: 0.011 (should be ~0)\n",
      "Epoch 2/3\n",
      "Progress: 10.0%\n",
      "Weight before: 0.019571759\n",
      "\n",
      "Weight after:  0.01957579\n",
      "Progress: 20.0%\n",
      "Weight before: 0.01957579\n",
      "\n",
      "Weight after:  0.019585334\n",
      "Progress: 30.0%\n",
      "Weight before: 0.019585334\n",
      "\n",
      "Weight after:  0.019581122\n",
      "Progress: 40.0%\n",
      "Weight before: 0.019581122\n",
      "\n",
      "Weight after:  0.019577729\n",
      "Progress: 50.0%\n",
      "Weight before: 0.019577729\n",
      "\n",
      "Weight after:  0.019581001\n",
      "Progress: 60.0%\n",
      "Weight before: 0.019581001\n",
      "\n",
      "Weight after:  0.019561376\n",
      "Progress: 70.0%\n",
      "Weight before: 0.019561376\n",
      "\n",
      "Weight after:  0.019582765\n",
      "Progress: 80.0%\n",
      "Weight before: 0.019582765\n",
      "\n",
      "Weight after:  0.019589437\n",
      "Progress: 90.0%\n",
      "Weight before: 0.019589437\n",
      "\n",
      "Weight after:  0.01954212\n",
      "Progress: 100.0%\n",
      "Weight before: 0.01954212\n",
      "\n",
      "Weight after:  0.019479465\n",
      "\n",
      "Epoch 2 Loss: 2.7782\n",
      "Avg Monet Score: 0.106 (should be ~1)\n",
      "Avg Photo Score: 0.098 (should be ~0)\n",
      "Epoch 3/3\n",
      "Progress: 10.0%\n",
      "Weight before: 0.019479465\n",
      "\n",
      "Weight after:  0.019454975\n",
      "Progress: 20.0%\n",
      "Weight before: 0.019454975\n",
      "\n",
      "Weight after:  0.01951956\n",
      "Progress: 30.0%\n",
      "Weight before: 0.01951956\n",
      "\n",
      "Weight after:  0.019552818\n",
      "Progress: 40.0%\n",
      "Weight before: 0.019552818\n",
      "\n",
      "Weight after:  0.019530913\n",
      "Progress: 50.0%\n",
      "Weight before: 0.019530913\n",
      "\n",
      "Weight after:  0.019515602\n",
      "Progress: 60.0%\n",
      "Weight before: 0.019515602\n",
      "\n",
      "Weight after:  0.01950109\n",
      "Progress: 70.0%\n",
      "Weight before: 0.01950109\n",
      "\n",
      "Weight after:  0.019505272\n",
      "Progress: 80.0%\n",
      "Weight before: 0.019505272\n",
      "\n",
      "Weight after:  0.019496715\n",
      "Progress: 90.0%\n",
      "Weight before: 0.019496715\n",
      "\n",
      "Weight after:  0.019500524\n",
      "Progress: 100.0%\n",
      "Weight before: 0.019500524\n",
      "\n",
      "Weight after:  0.019508181\n",
      "\n",
      "Epoch 3 Loss: 1.4316\n",
      "Avg Monet Score: 0.212 (should be ~1)\n",
      "Avg Photo Score: 0.183 (should be ~0)\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "\n",
    "my_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "training_monet_ds = iter(monet_ds.shuffle(1000).repeat())\n",
    "training_images_ds = iter(images_ds.shuffle(100).repeat())\n",
    "\n",
    "my_descrim = build_discriminator()\n",
    "\n",
    "\n",
    "# Calculate accuracy on test batches\n",
    "test_monet = next(training_monet_ds) \n",
    "test_images = next(training_images_ds)\n",
    "\n",
    "monet_preds = my_descrim(test_monet)\n",
    "images_preds = my_descrim(test_images)\n",
    "\n",
    "# Calculate accuracy (% correct classifications)\n",
    "monet_accuracy = tf.reduce_mean(tf.cast(monet_preds > 0.5, tf.float32))\n",
    "images_accuracy = tf.reduce_mean(tf.cast(images_preds < 0.5, tf.float32))\n",
    "total_accuracy = (monet_accuracy + images_accuracy) / 2\n",
    "\n",
    "print(f\"Monet Classification Accuracy: {monet_accuracy:.2%}\")\n",
    "print(f\"Photo Classification Accuracy: {images_accuracy:.2%}\") \n",
    "print(f\"Total Accuracy: {total_accuracy:.2%}\\n\")\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for iteration in range(epoch_length):\n",
    "        #if iteration % 10 == 0:\n",
    "        print(f\"\\rProgress: {(iteration+1)/epoch_length*100:.1f}%\", end=\"\")\n",
    "            \n",
    "        monet_images = preprocess_image(next(training_monet_ds))\n",
    "        photo_images = preprocess_image(next(training_images_ds))\n",
    "        \n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            monet_output = my_descrim(monet_images)\n",
    "            photo_output = my_descrim(photo_images)\n",
    "\n",
    "            loss = domain_discrimination_loss(monet_output, photo_output)\n",
    "\n",
    "        grads = tape.gradient(loss, my_descrim.trainable_variables)\n",
    "\n",
    "\n",
    "        print(f\"\\nWeight before:\", my_descrim.layers[1].weights[0][0,0,0,0].numpy())\n",
    "\n",
    "        # apply gradients\n",
    "        my_optimizer.apply_gradients(zip(grads, my_descrim.trainable_variables))\n",
    "\n",
    "        print(f\"\\nWeight after: \", my_descrim.layers[1].weights[0][0,0,0,0].numpy())           \n",
    "\n",
    "        # Print loss and accuracy metrics after each epoch\n",
    "        if iteration == epoch_length - 1:\n",
    "            print(f\"\\nEpoch {epoch+1} Loss: {loss:.4f}\")\n",
    "\n",
    "            # Calculate accuracy on test batches\n",
    "            test_monet = next(training_monet_ds) \n",
    "            test_images = next(training_images_ds)\n",
    "\n",
    "            monet_preds = my_descrim(test_monet)\n",
    "            photo_preds = my_descrim(test_images)\n",
    "\n",
    "            monet_score = tf.reduce_mean(monet_preds)\n",
    "            photo_score = tf.reduce_mean(photo_preds)\n",
    "\n",
    "            print(f\"Avg Monet Score: {monet_score:.3f} (should be ~1)\")\n",
    "            print(f\"Avg Photo Score: {photo_score:.3f} (should be ~0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
