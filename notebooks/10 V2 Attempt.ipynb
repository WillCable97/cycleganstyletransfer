{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7ikmriPSr2bk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, LeakyReLU, Input, Activation, Lambda, Add, UpSampling2D\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptDsK8FRr2bn"
   },
   "source": [
    "## Get data set objects together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E-rrOtiwr2bp"
   },
   "outputs": [],
   "source": [
    "#Environmnet stuff\n",
    "ROOT_PATH = \"./\"\n",
    "MODEL_NAME = \"LowFidelityGAN_V2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3105,
     "status": "ok",
     "timestamp": 1750822776466,
     "user": {
      "displayName": "William Cable",
      "userId": "04663351666127960465"
     },
     "user_tz": -600
    },
    "id": "7TofHvKqr2br",
    "outputId": "5633eb1e-5e74-4780-925e-79070613aa76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-01 17:52:17.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcycleganstyletransfer.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\willi\\Desktop\\AIPortfolio\\CycleGanV2\\cycleganstyletransfer\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193 files belonging to 1 classes.\n",
      "Using 1074 files for training.\n",
      "Using 119 files for validation.\n",
      "Found 7037 files belonging to 1 classes.\n",
      "Using 6334 files for training.\n",
      "Using 703 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Make the dataset\n",
    "from cycleganstyletransfer.config import DATA_DIR\n",
    "data_dir = DATA_DIR / \"raw\"\n",
    "\n",
    "\n",
    "my_monet_ds_train, my_monet_ds_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir / \"Monet\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(128, 128),\n",
    "    batch_size = 1,\n",
    "    labels = None,\n",
    ")\n",
    "\n",
    "my_image_ds_train, my_image_ds_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir / \"Images\",\n",
    "    validation_split=0.1,\n",
    "    subset=\"both\",\n",
    "    seed=42,\n",
    "    image_size=(128, 128),\n",
    "    batch_size = 1,\n",
    "    labels = None,\n",
    ")\n",
    "\n",
    "DATASET_HEIGHT = max(len(my_monet_ds_train), len(my_image_ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3c8PqtUxr2bs"
   },
   "outputs": [],
   "source": [
    "#Pre processing\n",
    "def augment_and_normalize(image):\n",
    "    image = tf.cast(image, tf.float32)  # convert from uint8\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=20)  # for 0–255 range\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "    image = image / 127.5 - 1.0  # scale to [-1, 1]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BBtoKfc_r2bt"
   },
   "outputs": [],
   "source": [
    "\n",
    "my_monet_ds_train = (\n",
    "  my_monet_ds_train\n",
    "  .map(augment_and_normalize, num_parallel_calls=AUTOTUNE)\n",
    "  .cache()\n",
    "  .shuffle(1000)\n",
    "  .repeat()\n",
    "  .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "my_image_ds_train = (\n",
    "  my_image_ds_train\n",
    "  .map(augment_and_normalize, num_parallel_calls=AUTOTUNE)\n",
    "  .cache()\n",
    "  .shuffle(1000)\n",
    "  .repeat()\n",
    "  .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "my_monet_ds_train = iter(my_monet_ds_train)\n",
    "my_image_ds_train = iter(my_image_ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qriZCxpEr2bu"
   },
   "source": [
    "## Define an Instance norm Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0sQCvMT7r2bv"
   },
   "outputs": [],
   "source": [
    "class InstanceNormalization(keras.layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        super(InstanceNormalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # One scale and bias per channel\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='ones',\n",
    "            trainable=True,\n",
    "            name='gamma'\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "            name='beta'\n",
    "        )\n",
    "        super(InstanceNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Compute mean and variance per instance, per channel\n",
    "        mean, variance = tf.nn.moments(inputs, axes=[1, 2], keepdims=True)\n",
    "        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
    "        return self.gamma * normalized + self.beta\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\"epsilon\": self.epsilon})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fshV5Byzr2bv"
   },
   "source": [
    "## Put the Discrim model together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1750822778700,
     "user": {
      "displayName": "William Cable",
      "userId": "04663351666127960465"
     },
     "user_tz": -600
    },
    "id": "S9GZY9LRr2bw",
    "outputId": "0b6ae39f-132b-4394-8e5c-cfa384bf47f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PatchGAN_70x70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 128)       131200    \n",
      "                                                                 \n",
      " instance_normalization (In  (None, 32, 32, 128)       256       \n",
      " stanceNormalization)                                            \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 256)       524544    \n",
      "                                                                 \n",
      " instance_normalization_1 (  (None, 16, 16, 256)       512       \n",
      " InstanceNormalization)                                          \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 512)       2097664   \n",
      "                                                                 \n",
      " instance_normalization_2 (  (None, 16, 16, 512)       1024      \n",
      " InstanceNormalization)                                          \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 1)         8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2766529 (10.55 MB)\n",
      "Trainable params: 2766529 (10.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator(input_shape=(128, 128, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(512, kernel_size=4, strides=1, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "\n",
    "    return Model(inputs, x, name='PatchGAN_70x70')\n",
    "\n",
    "my_patchgan_discriminator = build_discriminator()\n",
    "my_patchgan_discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1750822778822,
     "user": {
      "displayName": "William Cable",
      "userId": "04663351666127960465"
     },
     "user_tz": -600
    },
    "id": "A0AH1S6lXTG6",
    "outputId": "8bc9ea0a-fbe0-4093-e921-754d04ecdb3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PatchGAN_70x70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 128)       131200    \n",
      "                                                                 \n",
      " instance_normalization_3 (  (None, 32, 32, 128)       256       \n",
      " InstanceNormalization)                                          \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 256)       524544    \n",
      "                                                                 \n",
      " instance_normalization_4 (  (None, 16, 16, 256)       512       \n",
      " InstanceNormalization)                                          \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 512)       2097664   \n",
      "                                                                 \n",
      " instance_normalization_5 (  (None, 16, 16, 512)       1024      \n",
      " InstanceNormalization)                                          \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 1)         8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2766529 (10.55 MB)\n",
      "Trainable params: 2766529 (10.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_weak_discriminator(input_shape=(128, 128, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(1, kernel_size=4, strides=1, padding='same')(x)\n",
    "\n",
    "    return Model(inputs, x, name='PatchGAN_70x70')\n",
    "\n",
    "my_patchgan_discriminator = build_discriminator()\n",
    "my_patchgan_discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNlRxKjir2bx"
   },
   "source": [
    "## Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9z8CJKP_r2bx"
   },
   "outputs": [],
   "source": [
    "# === Reflection Padding ===\n",
    "def ReflectionPad2D(pad):\n",
    "    return Lambda(lambda x: tf.pad(x, [[0, 0], [pad, pad], [pad, pad], [0, 0]], mode='REFLECT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fMn7isUZr2by"
   },
   "outputs": [],
   "source": [
    "# === Residual Block ===\n",
    "def ResidualBlock(filters, kernel_size=3):\n",
    "    pad = kernel_size // 2\n",
    "    def block(x):\n",
    "        y = ReflectionPad2D(pad)(x)\n",
    "        y = Conv2D(filters, kernel_size, padding='valid')(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "\n",
    "        y = ReflectionPad2D(pad)(y)\n",
    "        y = Conv2D(filters, kernel_size, padding='valid')(y)\n",
    "        y = InstanceNormalization()(y)\n",
    "\n",
    "        return Add()([x, y])\n",
    "    return block\n",
    "##No activation at the end ?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1750822781713,
     "user": {
      "displayName": "William Cable",
      "userId": "04663351666127960465"
     },
     "user_tz": -600
    },
    "id": "WIvCXAv0r2bz",
    "outputId": "f8087b39-9e1e-4a3e-b8b1-f563339c981f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"JohnsonGenerator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " lambda_90 (Lambda)          (None, 134, 134, 3)          0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 128, 128, 64)         9472      ['lambda_90[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_114  (None, 128, 128, 64)         128       ['conv2d_124[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 128, 128, 64)         0         ['instance_normalization_114[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 64, 64, 128)          73856     ['activation_69[0][0]']       \n",
      "                                                                                                  \n",
      " instance_normalization_115  (None, 64, 64, 128)          256       ['conv2d_125[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, 64, 64, 128)          0         ['instance_normalization_115[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 32, 32, 256)          295168    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " instance_normalization_116  (None, 32, 32, 256)          512       ['conv2d_126[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_116[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_91 (Lambda)          (None, 34, 34, 256)          0         ['activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_91[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_117  (None, 32, 32, 256)          512       ['conv2d_127[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_117[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_92 (Lambda)          (None, 34, 34, 256)          0         ['activation_72[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_92[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_118  (None, 32, 32, 256)          512       ['conv2d_128[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, 32, 32, 256)          0         ['activation_71[0][0]',       \n",
      "                                                                     'instance_normalization_118[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_93 (Lambda)          (None, 34, 34, 256)          0         ['add_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_93[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_119  (None, 32, 32, 256)          512       ['conv2d_129[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_119[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_94 (Lambda)          (None, 34, 34, 256)          0         ['activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_94[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_120  (None, 32, 32, 256)          512       ['conv2d_130[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_40 (Add)                (None, 32, 32, 256)          0         ['add_39[0][0]',              \n",
      "                                                                     'instance_normalization_120[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_95 (Lambda)          (None, 34, 34, 256)          0         ['add_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_95[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_121  (None, 32, 32, 256)          512       ['conv2d_131[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_121[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_96 (Lambda)          (None, 34, 34, 256)          0         ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_96[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_122  (None, 32, 32, 256)          512       ['conv2d_132[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_41 (Add)                (None, 32, 32, 256)          0         ['add_40[0][0]',              \n",
      "                                                                     'instance_normalization_122[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_97 (Lambda)          (None, 34, 34, 256)          0         ['add_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_97[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_123  (None, 32, 32, 256)          512       ['conv2d_133[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_123[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_98 (Lambda)          (None, 34, 34, 256)          0         ['activation_75[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_98[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_124  (None, 32, 32, 256)          512       ['conv2d_134[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_42 (Add)                (None, 32, 32, 256)          0         ['add_41[0][0]',              \n",
      "                                                                     'instance_normalization_124[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_99 (Lambda)          (None, 34, 34, 256)          0         ['add_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_99[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_125  (None, 32, 32, 256)          512       ['conv2d_135[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_125[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_100 (Lambda)         (None, 34, 34, 256)          0         ['activation_76[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_100[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_126  (None, 32, 32, 256)          512       ['conv2d_136[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_43 (Add)                (None, 32, 32, 256)          0         ['add_42[0][0]',              \n",
      "                                                                     'instance_normalization_126[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_101 (Lambda)         (None, 34, 34, 256)          0         ['add_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_101[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_127  (None, 32, 32, 256)          512       ['conv2d_137[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, 32, 32, 256)          0         ['instance_normalization_127[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_102 (Lambda)         (None, 34, 34, 256)          0         ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (None, 32, 32, 256)          590080    ['lambda_102[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_128  (None, 32, 32, 256)          512       ['conv2d_138[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " add_44 (Add)                (None, 32, 32, 256)          0         ['add_43[0][0]',              \n",
      "                                                                     'instance_normalization_128[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampli  (None, 64, 64, 256)          0         ['add_44[0][0]']              \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (None, 64, 64, 128)          295040    ['up_sampling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " instance_normalization_129  (None, 64, 64, 128)          256       ['conv2d_139[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, 64, 64, 128)          0         ['instance_normalization_129[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampli  (None, 128, 128, 128)        0         ['activation_78[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (None, 128, 128, 64)         73792     ['up_sampling2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " instance_normalization_130  (None, 128, 128, 64)         128       ['conv2d_140[0][0]']          \n",
      "  (InstanceNormalization)                                                                         \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, 128, 128, 64)         0         ['instance_normalization_130[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " lambda_103 (Lambda)         (None, 134, 134, 64)         0         ['activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, 128, 128, 3)          9411      ['lambda_103[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7845123 (29.93 MB)\n",
      "Trainable params: 7845123 (29.93 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Generator(input_shape=(128, 128, 3), n_res_blocks=6):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = ReflectionPad2D(3)(inputs)\n",
    "    x = Conv2D(64, kernel_size=7, padding='valid')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Residual Blocks\n",
    "    for _ in range(n_res_blocks):\n",
    "        x = ResidualBlock(256)(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding='same')(x)\n",
    "    x = InstanceNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = ReflectionPad2D(3)(x)\n",
    "    x = Conv2D(3, kernel_size=7, padding='valid', activation='tanh')(x)\n",
    "\n",
    "    return Model(inputs, x, name='JohnsonGenerator')\n",
    "\n",
    "# Example:\n",
    "gen = Generator(input_shape=(128,128,3))\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXS7R-gJr2b0"
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QOxo7AgUr2b0"
   },
   "outputs": [],
   "source": [
    "\n",
    "#L2 Loss function\n",
    "def my_square_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "#Generator loss function\n",
    "def generator_loss(descrim_output):\n",
    "        return tf.reduce_mean(tf.math.squared_difference(tf.ones_like(descrim_output), descrim_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3F6n6-wr2b1"
   },
   "source": [
    "## Image buffer to stabilise training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3A3oWcGZr2b1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ImageBuffer:\n",
    "    \"\"\"\n",
    "    Implements a buffer that stores previously generated images.\n",
    "    When queried, it returns a mix of old and new images.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size=50):\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def query(self, image):\n",
    "        if len(self.data) < self.max_size:\n",
    "            # Buffer not full: store and return current fake\n",
    "            self.data.append(image)\n",
    "            return image\n",
    "        else:\n",
    "            if np.random.rand() > 0.5:\n",
    "                # Use buffer: pick old, swap with current\n",
    "                idx = np.random.randint(0, self.max_size)\n",
    "                old_image = self.data[idx]\n",
    "                self.data[idx] = image\n",
    "                return old_image\n",
    "            else:\n",
    "                # Use current fake\n",
    "                return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n271GsIyBM5S"
   },
   "source": [
    "## Add in decay schedule object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xq_6jwI_BQeB"
   },
   "outputs": [],
   "source": [
    "class LinearDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_lr, decay_start_epoch, total_epochs, steps_per_epoch):\n",
    "        super().__init__()\n",
    "        self.initial_lr = initial_lr\n",
    "        self.decay_start_epoch = tf.cast(decay_start_epoch, tf.float32)\n",
    "        self.total_epochs = tf.cast(total_epochs, tf.float32)\n",
    "        self.steps_per_epoch = tf.cast(steps_per_epoch, tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        epoch = tf.cast(step, tf.float32) / self.steps_per_epoch\n",
    "        lr = tf.cond(\n",
    "            epoch < self.decay_start_epoch,\n",
    "            lambda: self.initial_lr,\n",
    "            lambda: self.initial_lr * (1.0 - (epoch - self.decay_start_epoch) / (self.total_epochs - self.decay_start_epoch))\n",
    "        )\n",
    "        return tf.maximum(lr, 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERbgJp-Mr2b1"
   },
   "source": [
    "## Adding Alternating trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3bJcVnl3r2b1"
   },
   "outputs": [],
   "source": [
    "def to_display(img):\n",
    "    return (img[0] + 1) / 2 #* 0.5 + 0.5#tf.clip_by_value(img * 0.5 + 0.5, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xaV2m__Vr2b2"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# === CONFIG ===\n",
    "NUM_EPOCHS = 200\n",
    "EPOCH_LENGTH = DATASET_HEIGHT\n",
    "INITIAL_LR = 2e-4\n",
    "DECAY_START = 100\n",
    "\n",
    "# === TRACKERS ===\n",
    "current_epoch = tf.Variable(0, dtype=tf.int64)\n",
    "global_step = tf.Variable(0, dtype=tf.int64)\n",
    "\n",
    "DISPLAY_INTERVAL = 2  # record loss every 5 steps\n",
    "\n",
    "# Optimizers for all models\n",
    "monet_gen_opt = Adam(0.0, beta_1=0.5)\n",
    "photo_gen_opt = Adam(0.0, beta_1=0.5)\n",
    "monet_disc_opt = Adam(0.0, beta_1=0.5)\n",
    "photo_disc_opt = Adam(0.0, beta_1=0.5)\n",
    "\n",
    "# Initialize models\n",
    "monet_generator = Generator((128, 128, 3))\n",
    "photo_generator = Generator((128, 128, 3))\n",
    "monet_discriminator = build_weak_discriminator()\n",
    "photo_discriminator = build_discriminator()\n",
    "\n",
    "# Create buffers for each fake domain\n",
    "monet_fake_buffer = ImageBuffer(max_size=50)\n",
    "photo_fake_buffer = ImageBuffer(max_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pWcL9w6Jr2b2"
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def train_step(monet_image, photo_image, bool_val):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # === Generate fakes ===\n",
    "        fake_monet = monet_generator(photo_image, training=True)\n",
    "        fake_photo = photo_generator(monet_image, training=True)\n",
    "\n",
    "        # === Cycle back ===\n",
    "        cycled_photo = photo_generator(fake_monet, training=True)\n",
    "        cycled_monet = monet_generator(fake_photo, training=True)\n",
    "\n",
    "        # === Identity mapping ===\n",
    "        same_monet = monet_generator(monet_image, training=True)\n",
    "        same_photo = photo_generator(photo_image, training=True)\n",
    "\n",
    "        # === Discriminator real ===\n",
    "        disc_real_monet = monet_discriminator(monet_image, training=True)\n",
    "        disc_real_photo = photo_discriminator(photo_image, training=True)\n",
    "\n",
    "        # === Use buffer for discriminator fakes ===\n",
    "        fake_monet_for_disc = monet_fake_buffer.query(fake_monet)\n",
    "        fake_photo_for_disc = photo_fake_buffer.query(fake_photo)\n",
    "\n",
    "        disc_fake_monet = monet_discriminator(fake_monet_for_disc, training=True)\n",
    "        disc_fake_photo = photo_discriminator(fake_photo_for_disc, training=True)\n",
    "\n",
    "        # === Losses ===\n",
    "        monet_disc_loss = 0.5 * (\n",
    "            my_square_loss(tf.ones_like(disc_real_monet), disc_real_monet) +\n",
    "            my_square_loss(tf.zeros_like(disc_fake_monet), disc_fake_monet)\n",
    "        )\n",
    "        photo_disc_loss = 0.5 * (\n",
    "            my_square_loss(tf.ones_like(disc_real_photo), disc_real_photo) +\n",
    "            my_square_loss(tf.zeros_like(disc_fake_photo), disc_fake_photo)\n",
    "        )\n",
    "\n",
    "        monet_gen_loss = my_square_loss(tf.ones_like(\n",
    "            monet_discriminator(fake_monet, training=True)\n",
    "        ), monet_discriminator(fake_monet, training=True))\n",
    "        photo_gen_loss = my_square_loss(tf.ones_like(\n",
    "            photo_discriminator(fake_photo, training=True)\n",
    "        ), photo_discriminator(fake_photo, training=True))\n",
    "\n",
    "        cycle_loss = tf.reduce_mean(tf.abs(photo_image - cycled_photo)) + \\\n",
    "                     tf.reduce_mean(tf.abs(monet_image - cycled_monet))\n",
    "\n",
    "        identity_loss = tf.reduce_mean(tf.abs(monet_image - same_monet)) + \\\n",
    "                        tf.reduce_mean(tf.abs(photo_image - same_photo))\n",
    "\n",
    "        total_monet_gen_loss = monet_gen_loss + 10 * cycle_loss + 5 * identity_loss\n",
    "        total_photo_gen_loss = photo_gen_loss + 10 * cycle_loss + 5 * identity_loss\n",
    "\n",
    "    # === Apply gradients ===\n",
    "    #monet_disc_grads = tape.gradient(monet_disc_loss, monet_discriminator.trainable_variables)\n",
    "    #photo_disc_grads = tape.gradient(photo_disc_loss, photo_discriminator.trainable_variables)\n",
    "    monet_gen_grads = tape.gradient(total_monet_gen_loss, monet_generator.trainable_variables)\n",
    "    photo_gen_grads = tape.gradient(total_photo_gen_loss, photo_generator.trainable_variables)\n",
    "    monet_gen_opt.apply_gradients(zip(monet_gen_grads, monet_generator.trainable_variables))\n",
    "    photo_gen_opt.apply_gradients(zip(photo_gen_grads, photo_generator.trainable_variables))\n",
    "\n",
    "    if bool_val:\n",
    "        monet_disc_opt.apply_gradients(zip(monet_disc_grads, monet_discriminator.trainable_variables))\n",
    "        photo_disc_opt.apply_gradients(zip(photo_disc_grads, photo_discriminator.trainable_variables))\n",
    "        monet_disc_grads = tape.gradient(monet_disc_loss, monet_discriminator.trainable_variables)\n",
    "        photo_disc_grads = tape.gradient(photo_disc_loss, photo_discriminator.trainable_variables)\n",
    "\n",
    "\n",
    "    return (\n",
    "        monet_disc_loss, photo_disc_loss,\n",
    "        monet_gen_loss, photo_gen_loss,\n",
    "        cycle_loss, identity_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "iXWSGyufr2b3"
   },
   "outputs": [],
   "source": [
    "def setup_cyclegan_checkpoint():\n",
    "    \"\"\"\n",
    "    Sets up CycleGAN checkpoint manager using global models & ALL FOUR optimizers.\n",
    "    Uses these global variables:\n",
    "      monet_generator, photo_generator,\n",
    "      monet_discriminator, photo_discriminator,\n",
    "      monet_gen_opt, photo_gen_opt, monet_disc_opt, photo_disc_opt\n",
    "    \"\"\"\n",
    "    global ckpt, ckpt_manager, current_epoch  # make them global\n",
    "\n",
    "    # Ensure epoch is a tf.Variable if not already set\n",
    "    if 'current_epoch' not in globals():\n",
    "        current_epoch = tf.Variable(1, name=\"epoch\", trainable=False)\n",
    "\n",
    "    ckpt = tf.train.Checkpoint(\n",
    "        monet_generator=monet_generator,\n",
    "        photo_generator=photo_generator,\n",
    "        monet_discriminator=monet_discriminator,\n",
    "        photo_discriminator=photo_discriminator,\n",
    "        monet_gen_opt=monet_gen_opt,\n",
    "        photo_gen_opt=photo_gen_opt,\n",
    "        monet_disc_opt=monet_disc_opt,\n",
    "        photo_disc_opt=photo_disc_opt,\n",
    "        global_step=global_step,\n",
    "        epoch=current_epoch\n",
    "    )\n",
    "\n",
    "    ckpt_manager = tf.train.CheckpointManager(\n",
    "        ckpt,\n",
    "        f\"{ROOT_PATH}/checkpoints/{MODEL_NAME}\",\n",
    "        max_to_keep=20\n",
    "    )\n",
    "\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()\n",
    "        print(f\"✅ Restored from {ckpt_manager.latest_checkpoint} (epoch {int(current_epoch.numpy())})\")\n",
    "    else:\n",
    "        print(\"🚀 Training from scratch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 890
    },
    "executionInfo": {
     "elapsed": 5022,
     "status": "ok",
     "timestamp": 1750830241536,
     "user": {
      "displayName": "William Cable",
      "userId": "04663351666127960465"
     },
     "user_tz": -600
    },
    "id": "BlnNWX7Ps7OJ",
    "outputId": "8e0d31cc-59c6-49b5-9109-19cf22ebf4b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "LowFidelityGAN_V2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-11712530f8ad315d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-11712530f8ad315d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 63994;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(ROOT_PATH)\n",
    "print(MODEL_NAME)\n",
    "\n",
    "%load_ext tensorboard\n",
    "logdir = f\"{ROOT_PATH}/logs/{MODEL_NAME}\"\n",
    "%tensorboard --logdir \"$logdir\" --port 0  # let Colab pick a port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1CH4eLsr2b4",
    "outputId": "9dac7960-46f7-4726-c8b4-673e206fbc0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Restored from /content/drive/MyDrive/Colab Projects/CycleGan/checkpoints/LowFidelityGAN_V1_Decay/ckpt-9 (epoch 43)\n",
      "\n",
      "Epoch 1/100\n",
      "Step 6334/6334\n",
      "Epoch 1 done in 700s.\n",
      "\n",
      "Epoch 2/100\n",
      "Step 6334/6334\n",
      "Epoch 2 done in 527s.\n",
      "\n",
      "Epoch 3/100\n",
      "Step 6334/6334\n",
      "Epoch 3 done in 527s.\n",
      "\n",
      "Epoch 4/100\n",
      "Step 6334/6334\n",
      "Epoch 4 done in 527s.\n",
      "\n",
      "Epoch 5/100\n",
      "✅ Saved checkpoint for epoch 5: /content/drive/MyDrive/Colab Projects/CycleGan/checkpoints/LowFidelityGAN_V1_Decay/ckpt-10\n",
      "Step 6334/6334\n",
      "Epoch 5 done in 537s.\n",
      "\n",
      "Epoch 6/100\n",
      "Step 6334/6334\n",
      "Epoch 6 done in 527s.\n",
      "\n",
      "Epoch 7/100\n",
      "Step 6334/6334\n",
      "Epoch 7 done in 526s.\n",
      "\n",
      "Epoch 8/100\n",
      "Step 6334/6334\n",
      "Epoch 8 done in 527s.\n",
      "\n",
      "Epoch 9/100\n",
      "Step 6334/6334\n",
      "Epoch 9 done in 526s.\n",
      "\n",
      "Epoch 10/100\n",
      "✅ Saved checkpoint for epoch 10: /content/drive/MyDrive/Colab Projects/CycleGan/checkpoints/LowFidelityGAN_V1_Decay/ckpt-11\n",
      "Step 6334/6334\n",
      "Epoch 10 done in 531s.\n",
      "\n",
      "Epoch 11/100\n",
      "Step 6334/6334\n",
      "Epoch 11 done in 526s.\n",
      "\n",
      "Epoch 12/100\n",
      "Step 6334/6334\n",
      "Epoch 12 done in 526s.\n",
      "\n",
      "Epoch 13/100\n",
      "Step 6334/6334\n",
      "Epoch 13 done in 527s.\n",
      "\n",
      "Epoch 14/100\n",
      "Step 1746/6334"
     ]
    }
   ],
   "source": [
    "running_loss = []\n",
    "\n",
    "from datetime import datetime\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f\"{ROOT_PATH}/logs/{MODEL_NAME}/{current_time}DescrimOn3\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "\n",
    "dummy = tf.zeros([1, 128, 128, 3])\n",
    "_ = monet_generator(dummy)\n",
    "_ = photo_generator(dummy)\n",
    "_ = monet_discriminator(dummy)\n",
    "_ = photo_discriminator(dummy)\n",
    "\n",
    "lr_schedule = LinearDecay(INITIAL_LR, DECAY_START, NUM_EPOCHS, EPOCH_LENGTH)\n",
    "\n",
    "monet_gen_opt = Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
    "photo_gen_opt = Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
    "monet_disc_opt = Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
    "photo_disc_opt = Adam(learning_rate=lr_schedule, beta_1=0.5)\n",
    "\n",
    "setup_cyclegan_checkpoint()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    epoch_losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_path = ckpt_manager.save()\n",
    "        print(f\"✅ Saved checkpoint for epoch {epoch + 1}: {save_path}\")\n",
    "\n",
    "        monet_generator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_monet_generator.weights.h5\")\n",
    "        photo_generator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_photo_generator.weights.h5\")\n",
    "        monet_discriminator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_monet_discriminator.weights.h5\")\n",
    "        photo_discriminator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_photo_discriminator.weights.h5\")\n",
    "\n",
    "\n",
    "    for step in range(EPOCH_LENGTH):\n",
    "        monet_image = next(my_monet_ds_train)\n",
    "        photo_image = next(my_image_ds_train)\n",
    "\n",
    "        losses = train_step(monet_image, photo_image, ((step % 3) == 0))\n",
    "\n",
    "        global_step.assign_add(1)\n",
    "\n",
    "        loss_vals = [tf.squeeze(l).numpy() for l in losses]\n",
    "\n",
    "        #global_step = epoch * EPOCH_LENGTH + step\n",
    "\n",
    "        # Add to running buffer\n",
    "        running_loss.append(loss_vals)\n",
    "\n",
    "        if step % DISPLAY_INTERVAL == 0:\n",
    "            avg_running_loss = np.mean(running_loss, axis=0)\n",
    "\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"Avg100/M_disc\", avg_running_loss[0], step=global_step)\n",
    "                tf.summary.scalar(\"Avg100/P_disc\", avg_running_loss[1], step=global_step)\n",
    "                tf.summary.scalar(\"Avg100/M_gen\", avg_running_loss[2], step=global_step)\n",
    "                tf.summary.scalar(\"Avg100/P_gen\", avg_running_loss[3], step=global_step)\n",
    "                tf.summary.scalar(\"Avg100/Cycle\", avg_running_loss[4], step=global_step)\n",
    "                tf.summary.scalar(\"Avg100/Identity\", avg_running_loss[5], step=global_step)\n",
    "                tf.summary.scalar(\"LearningRate\", lr_schedule(global_step), step=global_step)\n",
    "\n",
    "                # 1️⃣  Get real samples\n",
    "                real_photo = photo_image\n",
    "                real_monet = monet_image\n",
    "\n",
    "                # 2️⃣  Generate mappings\n",
    "                generated_monet = monet_generator(real_photo, training=False)\n",
    "                generated_photo = photo_generator(real_monet, training=False)\n",
    "\n",
    "                # 3️⃣  Convert to displayable (your existing function)\n",
    "                real_photo_disp = to_display(real_photo)\n",
    "                generated_monet_disp = to_display(generated_monet)\n",
    "                real_monet_disp = to_display(real_monet)\n",
    "                generated_photo_disp = to_display(generated_photo)\n",
    "\n",
    "                # 4️⃣  Stack into a 2x2 grid (rows)\n",
    "                row1 = tf.concat([real_photo_disp, generated_monet_disp], axis=1)\n",
    "                row2 = tf.concat([real_monet_disp, generated_photo_disp], axis=1)\n",
    "                grid = tf.concat([row1, row2], axis=0)\n",
    "\n",
    "                # 5️⃣  Make sure it's float32 and has batch dimension\n",
    "                grid = tf.convert_to_tensor(grid, dtype=tf.float32)\n",
    "                grid = tf.expand_dims(grid, 0)  # add batch dimension\n",
    "\n",
    "                # 6️⃣  Log it as a single image\n",
    "                tf.summary.image(\"Grid/2x2_Examples\", grid, step=global_step)\n",
    "\n",
    "\n",
    "            running_loss = []  # reset for next 100 steps\n",
    "        print(f\"\\rStep {step+1}/{EPOCH_LENGTH}\", end='')\n",
    "    current_epoch.assign_add(1)\n",
    "\n",
    "    #avg_losses = np.mean(epoch_losses, axis=0)\n",
    "    print(f\"\\nEpoch {epoch + 1} done in {int(time.time()-start_time)}s.\")\n",
    "    #all_losses.extend(epoch_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jD13w6ZUr2b4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0eAxZ0qr2b5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L33IBcpXr2b5"
   },
   "outputs": [],
   "source": [
    "save_path = ckpt_manager.save()\n",
    "#print(f\"✅ Saved checkpoint for epoch {epoch + 1}: {save_path}\")\n",
    "\n",
    "monet_generator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_monet_generator.weights.h5\")\n",
    "photo_generator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_photo_generator.weights.h5\")\n",
    "monet_discriminator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_monet_discriminator.weights.h5\")\n",
    "photo_discriminator.save_weights(f\"{ROOT_PATH}/models/{MODEL_NAME}_photo_discriminator.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VSH6A2dr2b5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w9qmCNZr2b5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWliAzB0oVkR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q34yXqmvf1s_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLlxfpW2f1wI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UC-xqLpLf1zO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7BI5E5Kf119"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  photo_image = next(my_image_ds_train)\n",
    "  test_photo_to_monet = monet_generator(photo_image, training=False)\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(to_display(photo_image))\n",
    "  plt.title('Input Photo')\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(to_display(test_photo_to_monet))\n",
    "  plt.title('Generated Monet')\n",
    "  plt.show()\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f3XOCM8f147"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7xyBRkKf17o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "typTwVAGf1-Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
